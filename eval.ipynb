{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load questions from JSON file\n",
    "with open('data/eval_data/questions.json', 'r') as file:\n",
    "    questions_data = json.load(file)\n",
    "\n",
    "questions_en = questions_data['en']\n",
    "questions_de = questions_data['de']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the OpenAI API client\n",
    "client = OpenAI()\n",
    "\n",
    "# Load the vector store ID and file paths from the pickle file\n",
    "with open('vector_store.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "vector_store_id = data['vector_store_id']\n",
    "\n",
    "# Create and update the assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Product Documentation Assistant\",\n",
    "    instructions=\"\"\"You are a knowledgeable product support assistant for specific lighting products. \n",
    "    Use the provided documents to answer user queries about product specifications, usage guidelines, \n",
    "    and other relevant details ONLY for the products mentioned in these documents.\n",
    "    Make sure you answet in the language of the provided query. \n",
    "    If a question is about any topic or product not covered in the provided documents, \n",
    "    including other companies products, respond with \"I don't have information about that.\" \n",
    "    I can only provide details about the specific lighting products in my documentation.'\"\"\",\n",
    "    model=\"gpt-4o\",    \n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    ")\n",
    "\n",
    "\n",
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=assistant.id,\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store_id]}},\n",
    ")\n",
    "\n",
    "# Function to query questions and save responses\n",
    "def query_questions(questions, language):\n",
    "    results = []\n",
    "    for question in questions:\n",
    "        thread = client.beta.threads.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": question,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Create and poll the run\n",
    "        run = client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread.id, assistant_id=assistant.id\n",
    "        )\n",
    "\n",
    "        # List messages and capture response\n",
    "        messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "        message_content = messages[0].content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "        answer = {\n",
    "            \"question\": question,\n",
    "            \"answer\": message_content.value,\n",
    "            \"citations\": citations,\n",
    "            \"language\": language\n",
    "        }\n",
    "        results.append(answer)\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the questions in English and German\n",
    "results_en = query_questions(questions_en, \"en\")\n",
    "results_de = query_questions(questions_de, \"de\")\n",
    "\n",
    "# Save the results to a new JSON file\n",
    "with open('questions_answers_de.json', 'w') as file:\n",
    "    json.dump(results_de, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('questions_answers_en.json', 'w') as file:\n",
    "    json.dump(results_en, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Combine results\n",
    "all_results = results_en + results_de\n",
    "with open('questions_answers.json', 'w') as file:\n",
    "    json.dump(all_results, file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the nominal current of the XBO 2500 W/HS XL OFR lamp?\n",
      "Answer: The nominal current of the XBO 2500 W/HS XL OFR lamp is 90.00 A[0].\n",
      "Similarity Score: 0.9489970732787987\n",
      "Citations: ['[0] ZMP_1007189_XBO_2500_W_HS_XL_OFR.pdf']\n",
      "Language: en\n",
      "\n",
      "Question: How long is the XBO 2500 W/HS XL OFR lamp?\n",
      "Answer: The length of the XBO 2500 W/HS XL OFR lamp is 342.0 mm[0].\n",
      "Similarity Score: 0.8903802089344491\n",
      "Citations: ['[0] ZMP_1007189_XBO_2500_W_HS_XL_OFR.pdf']\n",
      "Language: en\n",
      "\n",
      "Question: What are the electrical specifications of the XBO 3000 W/H XL OFR lamp?\n",
      "Answer: The electrical specifications of the XBO 3000 W/H XL OFR lamp are as follows:\n",
      "\n",
      "- **Nominal Current:** 105 A\n",
      "- **Current Control Range:** 70…110 A\n",
      "- **Nominal Power:** 3000 W\n",
      "- **Nominal Voltage:** 28.0 V[0].\n",
      "Similarity Score: 0.9264885073200801\n",
      "Citations: ['[0] ZMP_1007191_XBO_3000_W_H_XL_OFR.pdf']\n",
      "Language: en\n",
      "\n",
      "Question: What is the lifespan of the XBO 3000 W/H XL OFR lamp?\n",
      "Answer: The lifespan of the XBO 3000 W/H XL OFR lamp is 2200 hours[0].\n",
      "Similarity Score: 0.941389279447421\n",
      "Citations: ['[0] ZMP_1007191_XBO_3000_W_H_XL_OFR.pdf']\n",
      "Language: en\n",
      "\n",
      "Question: What are the electrical specifications of the XBO 3000 W/HS XL OFR lamp?\n",
      "Answer: The electrical specifications of the XBO 3000 W/HS XL OFR lamp are as follows:\n",
      "\n",
      "- **Nominal Current**: 100 A\n",
      "- **Current Control Range**: 70 – 110 A\n",
      "- **Nominal Power**: 3000 W\n",
      "- **Nominal Voltage**: 29 V[0].\n",
      "Similarity Score: 0.9235451440488438\n",
      "Citations: ['[0] ZMP_1007193_XBO_3000_W_HS_XL_OFR.pdf']\n",
      "Language: en\n",
      "\n",
      "Average Similarity Score for English Questions: 0.9270140593589717\n",
      "Average Similarity Score for German Questions: 0.9123779145971224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Load the saved questions and answers from the JSON file\n",
    "with open('data/eval_data/questions_answers.json', 'r') as file:\n",
    "    qa_data = json.load(file)\n",
    "\n",
    "# Function to get embedding from OpenAI\n",
    "def get_embedding(text):\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Function to evaluate the responses\n",
    "def evaluate_responses(qa_data):\n",
    "    evaluation_results = []\n",
    "    for item in qa_data:\n",
    "        question = item['question']\n",
    "        answer = item['answer']\n",
    "\n",
    "        # Compute embeddings for question and answer\n",
    "        question_embedding = get_embedding(question)\n",
    "        answer_embedding = get_embedding(answer)\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        similarity_score = cosine_similarity(\n",
    "            [question_embedding], [answer_embedding]\n",
    "        )[0][0]\n",
    "\n",
    "        evaluation_results.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"similarity_score\": similarity_score,\n",
    "            \"citations\": item.get('citations', []),\n",
    "            \"language\": item['language']\n",
    "        })\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "# Evaluate the responses\n",
    "evaluation_results = evaluate_responses(qa_data)\n",
    "\n",
    "# Save the evaluation results to a new JSON file\n",
    "with open('evaluation_results.json', 'w') as file:\n",
    "    json.dump(evaluation_results, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Print some sample evaluation results\n",
    "for result in evaluation_results[:5]:  \n",
    "    print(f\"Question: {result['question']}\")\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    print(f\"Similarity Score: {result['similarity_score']}\")\n",
    "    print(f\"Citations: {result['citations']}\")\n",
    "    print(f\"Language: {result['language']}\")\n",
    "    print()\n",
    "\n",
    "# Compute and print average similarity scores for each language\n",
    "similarity_scores_en = [result['similarity_score'] for result in evaluation_results if result['language'] == 'en']\n",
    "similarity_scores_de = [result['similarity_score'] for result in evaluation_results if result['language'] == 'de']\n",
    "\n",
    "average_similarity_en = np.mean(similarity_scores_en)\n",
    "average_similarity_de = np.mean(similarity_scores_de)\n",
    "\n",
    "print(f\"Average Similarity Score for English Questions: {average_similarity_en}\")\n",
    "print(f\"Average Similarity Score for German Questions: {average_similarity_de}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
